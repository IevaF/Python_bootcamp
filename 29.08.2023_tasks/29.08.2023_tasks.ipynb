{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6636076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, max\n",
    "from pyspark.sql.functions import avg\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9252260d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Task (RDD):\n",
    "\n",
    "# Read a text file containing paragraphs and find the paragraph with the maximum number of words.\n",
    "# Hint: Use the textFile transformation, split paragraphs into words, and find the paragraph with the most words using the max action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1097cab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder.appName(\"WordCount\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "322a6301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the text file as an RDD\n",
    "text_rdd = sc.textFile(\"C:\\\\Ieva\\\\Python_Bootcamp\\\\Task folder\\\\29.08.2023_tasks\\\\Random_text.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60fac974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the paragraph with the most words using the max action\n",
    "max_words_paragraph = text_rdd \\\n",
    "    .map(lambda paragraph: (paragraph, len(paragraph.split()))) \\\n",
    "    .max(key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90724236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph with the most words:\n",
      "Far concluded not his something extremity. Want four we face an he gate. On he of played he ladies answer little though nature. Blessing oh do pleasure as so formerly. Took four spot soon led size you. Outlived it received he material. Him yourself joy moderate off repeated laughter outweigh screened.Friendship contrasted solicitude insipidity in introduced literature it. He seemed denote except as oppose do spring my. Between any may mention evening age shortly can ability regular. He shortly sixteen of colonel colonel evening cordial to. Although jointure an my of mistress servants am weddings. Age why the therefore education unfeeling for arranging. Above again money own scale maids ham least led. Returned settling produced strongly ecstatic use yourself way. Repulsive extremity enjoyment she perceived nor.He my polite be object oh change. Consider no mr am overcame yourself throwing sociable children. Hastily her totally conduct may. My solid by stuff first smile fanny. Humoured how advanced mrs elegance sir who. Home sons when them dine do want to. Estimating themselves unsatiable imprudence an he at an. Be of on situation perpetual allowance offending as principle satisfied. Improved carriage securing are desirous too.\n"
     ]
    }
   ],
   "source": [
    "print(\"Paragraph with the most words:\")\n",
    "print(max_words_paragraph[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "473dbe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.Task (Spark DataFrame):\n",
    "\n",
    "# Read a JSON file containing customer data (fields: name, age, purchases) and find the customers with the highest number of purchases.\n",
    "# Hint: Use the read.json method, the orderBy transformation, and the show action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d451e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating json file\n",
    "customer_data = [\n",
    "    {\"name\": \"Ilze\", \"age\": 30, \"purchases\": 4},\n",
    "    {\"name\": \"Karlis\", \"age\": 25, \"purchases\": 2},\n",
    "    {\"name\": \"Zane\", \"age\": 32, \"purchases\": 9},\n",
    "    {\"name\": \"Deivs\", \"age\": 24, \"purchases\": 10},\n",
    "    {\"name\": \"Atis\", \"age\": 28, \"purchases\": 7},\n",
    "    {\"name\": \"Laura\", \"age\": 15, \"purchases\": 2},\n",
    "]\n",
    "\n",
    "json_data = json.dumps(customer_data, indent=4)\n",
    "\n",
    "with open(\"customer_data.json\", \"w\") as file:\n",
    "    file.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2eb15102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder.appName(\"CustomerData\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78ed5ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define json file path\n",
    "json_file_path = \"C:\\\\Ieva\\\\Python_Bootcamp\\\\Task folder\\\\29.08.2023_tasks\\\\customer_data.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5ffcbea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSON data\n",
    "with open(json_file_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "27ae4bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame \n",
    "customer_df = spark.createDataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f4aabf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find customers with the highest number of purchases\n",
    "max_purchases = customer_df.select(\"name\", \"purchases\") \\\n",
    "    .orderBy(customer_df[\"purchases\"].desc()) \\\n",
    "    .limit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e001b58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+\n",
      "| name|purchases|\n",
      "+-----+---------+\n",
      "|Deivs|       10|\n",
      "+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_purchases.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ae459136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_corrupt_record: string]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I had a problem of reading json file using read.json method. It returned error which I couldn't fix:)\n",
    "json_file_path = \"C:\\\\Ieva\\\\Python_Bootcamp\\\\Task folder\\\\29.08.2023_tasks\\\\customer_data.json\"\n",
    "customer_df = spark.read.json(json_file_path)\n",
    "customer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1708d77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.Task (SQL with DataFrame):\n",
    "\n",
    "# Read two CSV files containing employee data and department data (columns: employee_id, name, department_id, department_name), \n",
    "# and find the department with the highest average employee age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e2e269c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating csv files\n",
    "\n",
    "employee_data = [\n",
    "    [\"employee_id\", \"name\", \"age\", \"department_id\"],\n",
    "    [1, \"Ilze\", 30, 101],\n",
    "    [2, \"Karlis\", 25, 102],\n",
    "    [3, \"Zane\", 32, 101],\n",
    "    [4, \"Deivs\", 24, 103],\n",
    "    [4, \"Atis\", 28, 103],\n",
    "    [5, \"Atis\", 28, 103],\n",
    "    [5, \"Laura\", 15, 103],\n",
    "]\n",
    "\n",
    "department_data = [\n",
    "    [\"department_id\", \"department_name\"],\n",
    "    [101, \"HR\"],\n",
    "    [102, \"Sales\"],\n",
    "    [103, \"Engineering\"]\n",
    "]\n",
    "\n",
    "employee_csv_file = \"employee_data.csv\"\n",
    "department_csv_file = \"department_data.csv\"\n",
    "\n",
    "with open(employee_csv_file, mode=\"w\", newline=\"\") as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    for row in employee_data:\n",
    "        csv_writer.writerow(row)\n",
    "\n",
    "with open(department_csv_file, mode=\"w\", newline=\"\") as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    for row in department_data:\n",
    "        csv_writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "44e9cb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder.appName(\"EmployeeDepartment\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0ac54f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV files\n",
    "employee_df = spark.read.csv(\"C:\\\\Ieva\\\\Python_Bootcamp\\\\Task folder\\\\29.08.2023_tasks\\\\employee_data.csv\", header=True, inferSchema=True)\n",
    "department_df = spark.read.csv(\"C:\\\\Ieva\\\\Python_Bootcamp\\\\Task folder\\\\29.08.2023_tasks\\\\department_data.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "888aabc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the employee and department DataFrames and calculate the average age per department\n",
    "joined_df = employee_df.join(department_df, \"department_id\", \"inner\")\n",
    "average_age_per_department = joined_df.groupBy(\"department_name\").agg(avg(\"age\").alias(\"avg_age\"))\n",
    "\n",
    "# Find the department with the highest average age\n",
    "max_avg_age_department = average_age_per_department.orderBy(average_age_per_department[\"avg_age\"].desc()).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "87fa5fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Department with the highest average age:\n",
      "Department Name: HR\n",
      "Average Age: 31.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Department with the highest average age:\")\n",
    "print(\"Department Name:\", max_avg_age_department[\"department_name\"])\n",
    "print(\"Average Age:\", max_avg_age_department[\"avg_age\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244462a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
